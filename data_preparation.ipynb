{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deadly-contents",
   "metadata": {},
   "source": [
    "# Libraries, Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conceptual-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pycountry\n",
    "import functools\n",
    "import calendar\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "serial-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the jupyter autocomplete issue\n",
    "%config Completer.use_jedi = False\n",
    "# adjust pandas settings to not display integers in scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structural-surgery",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read in data and set column names\n",
    "df = pd.read_csv(\"data/1.txt\", sep=':', header=None, names=[\"phone\", \"id\", \"f_name\", \"surname\", \"sex\", \"current_city\", \"hometown\", \"rel_status\", \"work\", \"join_date\", \"email\", \"dob\", \"13\", \"14\"], low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-maximum",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-conservation",
   "metadata": {},
   "source": [
    "## id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numerous-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the few rows without corresponding ids\n",
    "df = df.dropna(subset=['id'])\n",
    "# set the id column to integer type\n",
    "df['id'] = df['id'].astype('int')\n",
    "# sort the dataframe by id\n",
    "df = df.sort_values('id')\n",
    "# drop rows where there are duplicate ids (caused by multiple phone numbers associated with one account)\n",
    "df = df.drop_duplicates(subset='id', keep='first')\n",
    "# set the id column as the index\n",
    "df = df.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-effects",
   "metadata": {},
   "source": [
    "## phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "false-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the country code from the phone number\n",
    "df['country_code'] = df['phone'].apply(lambda x: str(x)[0:3])\n",
    "# remove the swedish country codes, which appear to be included with this irish data in error\n",
    "df = df.loc[df['country_code'] != '467']\n",
    "# extract the phone provider prefixes\n",
    "df['phone_prefix'] = df['phone'].apply(lambda x: '0' + str(x)[3:5])\n",
    "# drop the raw phone number and country code data\n",
    "df = df.drop(['phone', 'country_code'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-classification",
   "metadata": {},
   "source": [
    "## f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "controlled-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-manufacturer",
   "metadata": {},
   "source": [
    "## surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "considered-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-exposure",
   "metadata": {},
   "source": [
    "## sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chubby-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up some errors in the sex data\n",
    "df['sex'] = df['sex'].replace({'male (':'male'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-lucas",
   "metadata": {},
   "source": [
    "## current_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lucky-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_extractor(x):\n",
    "    \"\"\"\n",
    "    This function removes all but the rightmost segment of each address.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.notna(x):\n",
    "        if ',' in x:\n",
    "            return x.split(', ')[-1]\n",
    "        else:\n",
    "            return x\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "grand-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(None)\n",
    "def country_cleaner(x):\n",
    "    \"\"\"\n",
    "    This function attempts to match the rightmost segment of each address to a specific country, using the pycountry library.\n",
    "    This allows for standardisation for mapping purposes.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = pycountry.countries.search_fuzzy(x)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return result[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hungry-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_extractor(x):\n",
    "    \"\"\"\n",
    "    This function removes all but the leftmost segment of each address.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.notna(x):\n",
    "        if ',' in x:\n",
    "            return x.split(', ')[0]\n",
    "        else:\n",
    "            return x\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "negative-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only the leftmost section of each address\n",
    "df['current_country'] = df['current_city'].apply(lambda x: country_extractor(x))\n",
    "# attempt to match each leftmost address section to an actual country\n",
    "df['current_country'] = df['current_country'].apply(lambda x: country_cleaner(x))\n",
    "# extract only the rightmost section of each address\n",
    "df['current_city'] = df['current_city'].apply(lambda x: city_extractor(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-genetics",
   "metadata": {},
   "source": [
    "## hometown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "obvious-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only the leftmost section of each address\n",
    "df['hometown_country'] = df['hometown'].apply(lambda x: country_extractor(x))\n",
    "# attempt to match each leftmost address section to an actual country\n",
    "df['hometown_country'] = df['hometown_country'].apply(lambda x: country_cleaner(x))\n",
    "# remove ireland from the hometown_country data, to exclusively look at foreign countries\n",
    "df['hometown_country'] = df['hometown_country'].replace({'Ireland': np.nan})\n",
    "# extract only the rightmost section of each address\n",
    "df['hometown'] = df['hometown'].apply(lambda x: city_extractor(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-studio",
   "metadata": {},
   "source": [
    "## relationship_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dimensional-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-moisture",
   "metadata": {},
   "source": [
    "## work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "circular-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up and standardise some of the work data\n",
    "df['work'] = df['work'].replace(\n",
    "    {\n",
    "        'Health Service Executive': 'HSE',\n",
    "        'Dublin, Ireland': np.nan,\n",
    "        'Self employed': 'Self-Employed',\n",
    "        'Self Employed (Business)': 'Self-Employed',\n",
    "        'HSE West': 'HSE',\n",
    "        'Tesco Ireland': 'Tesco',\n",
    "        'Irish Defence Forces': 'Óglaigh na hÉireann / Irish Defence Forces',\n",
    "        'None': np.nan,\n",
    "        'HSE Ireland': 'HSE'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-castle",
   "metadata": {},
   "source": [
    "## join-date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "annoying-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_date_extractor(x):\n",
    "    \"\"\"\n",
    "    This function simply extracts the date from the datetime data.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.notna(x):\n",
    "        return x.split(' ')[0]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "working-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the join date from the datetime data\n",
    "df['join_date'] = df['join_date'].apply(lambda x: join_date_extractor(x))\n",
    "# correct for some dirty join_date data\n",
    "df['join_date'] = df['join_date'].replace({'1/1/0001': np.nan})\n",
    "# convert join_date column to datetime\n",
    "df['join_date'] = pd.to_datetime(df['join_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-dining",
   "metadata": {},
   "source": [
    "## email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "informed-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct for some dirty data\n",
    "df['email'] = df['email'].replace({0:np.nan, '00':np.nan})\n",
    "# correct for an error arising from inconsistencies in available data, which caused the import to place some data in varying columns\n",
    "df['email'] = df['email'].combine_first(df['13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "animated-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_provider_extractor(x):\n",
    "    \"\"\"\n",
    "    This function extracts the email domain from the email column.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.notna(x):\n",
    "        return x.split('@')[1]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aerial-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the email provider from the email data\n",
    "df['email_provider'] = df['email'].apply(lambda x: email_provider_extractor(x))\n",
    "# drop the raw email data\n",
    "df.drop('email', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-horse",
   "metadata": {},
   "source": [
    "## dob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "preliminary-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct for some dirty data\n",
    "df['dob'] = df['dob'].replace({'00 AM':np.nan})\n",
    "# correct for an error arising from inconsistencies in available data, which caused the import to place some data in varying columns\n",
    "df['dob'] = df['dob'].combine_first(df['14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "weighted-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def birth_month_extractor(x):\n",
    "    \"\"\"\n",
    "    This function extracts the birth month from the dob column.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.notna(x):\n",
    "        month = int(str(x)[0:2])\n",
    "        return calendar.month_name[month]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "worthy-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the birth month from the dob data\n",
    "df['birth_month'] = df['dob'].apply(lambda x: birth_month_extractor(x))\n",
    "# set any dob data which does not contain the year to nan\n",
    "df.loc[df['dob'].str.len() < 10, 'dob'] = np.nan\n",
    "# convert the dob column to datetime\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "# drop the now-unnecessary '13' and '14' columns\n",
    "df.drop(['13', '14'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "muslim-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate today's date\n",
    "today = pd.to_datetime(str(date.today()))\n",
    "# calculate the current age of users, based on their birthdate\n",
    "df['age'] = df['dob'].apply(lambda x: (today - x)).dt.days // 365\n",
    "# drop the dob column\n",
    "df.drop('dob', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-thailand",
   "metadata": {},
   "source": [
    "# Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "educational-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the cleaned data to a csv file, for subsequent import into Tableau\n",
    "df.to_csv('data/facebook_leak.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
